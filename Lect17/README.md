## DL4ES, Лекция 17

#### Семинар-тьюториал. Оптимизация и ускорение процессов подготовки, аугментации данных и передачи на GPU.



На этом семинаре обсуждается оптимизация обработки данных для подачи в нейросеть с целью ускорения вычислений. Основное внимание уделяется многопоточному исполнению, где разные потоки занимаются чтением, предобработкой и передачей данных на GPU. Проблема, с которой сталкиваются, это простои GPU из-за медленной обработки и передачи данных. Для решения этой проблемы предлагается распараллеливание задач, таких как чтение данных с диска, их аугментация и передача на GPU.

Ключевые моменты обсуждения:

1. **Бутылочные горлышки**: Основные замедления происходят на этапе предобработки данных и передачи их на GPU. Например, чтение данных или такие аугментации, как Elastic Transformation, могут быть очень ресурсоемкими и выполняться медленно на CPU.

2. **Распараллеливание задач**: Использование многопоточности для распараллеливания задач. Потоки обрабатывают данные независимо, но взаимодействуют через общие структуры данных, такие как очереди.

3. **Оптимизация чтения данных**: Для ускорения чтения данных предлагается хранить их на SSD, что значительно повышает скорость доступа по сравнению с традиционными HDD.

4. **Организация потоков**: Необходимо следить за тем, чтобы очередь данных на GPU наполнялась быстрее, чем при выполнении последовательных чтения и обработки данных, за счет увеличения количества потоков, которые заполняют эту очередь.

5. **Кэширование и блокировки**: Использование блокировок для предотвращения ошибок гонки данных, а также кэширование данных для уменьшения повторного чтения одной и той же информации.

6. **Генераторы и очереди**: Генераторы используются для последовательного извлечения данных, и они защищены от многопоточных конфликтов с помощью блокировок.



нейросеть, обработка данных, многопоточность, аугментация, gpu, cpu, оптимизация, очереди, распараллеливание, блокировки