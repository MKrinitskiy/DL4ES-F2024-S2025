## DL4ES, Лекция 2

#### Введение в машинное обучение в науках о Земле.



В этой лекции обсуждались различные модели машинного обучения, включая линейную и логистическую регрессии, а также более сложные модели, такие как искусственные нейронные сети. Основное внимание уделялось оптимизации этих моделей с помощью градиентных методов. В лекции объясняется, как градиентный спуск применяется для минимизации функции потерь, и подчеркнул важность выбора правильного темпа обучения (learning rate). Было рассмотрено, как неправильно выбранный темп обучения может привести к осцилляциям или даже к расхождению оптимизации. Также обсуждались методы улучшения сходимости, такие как нормализация данных и регуляризация, которые помогают справляться с проблемами, связанными с масштабом и корреляцией признаков. Кроме этого затрагивался вопрос диагностики оптимизации, в рамках которого рассматривался анализ эволюции функции потерь для понимания процесса обучения и стабилизации модели. Было упомянуто, что на практике критерии остановки часто игнорируются, и оптимизация проводится на фиксированное количество итераций. Также была затронута тема модификации шага обучения в процессе оптимизации для улучшения сходимости.



градиентный спуск, оптимизация, функция потерь, нейронные сети, темп обучения, нормализация, регуляризация, сходимость, параметрические модели, осцилляции